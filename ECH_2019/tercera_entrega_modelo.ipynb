{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8OAORuegWIZ",
        "outputId": "e4ad3c1d-39dd-4c8a-fd22-ef5ab6f8db95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NYSr_Xd_gXbe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, Normalizer\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/ECH_2019.csv')\n",
        "\n",
        "# df = pd.read_csv('ECH_2019.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eTWFbjwLgXYW"
      },
      "outputs": [],
      "source": [
        "# Reemplazar 0 que representa no hay respuesta\n",
        "no_data = {0: 'No hay dato', '0': 'No hay dato'}\n",
        "\n",
        "mask = df.columns.difference(\n",
        "    [\n",
        "        'edad',\n",
        "        'sueldo',\n",
        "        'hijos en hogar',\n",
        "        'hijos en otro hogar',\n",
        "        'hijos en el extranjero',\n",
        "        'suma_hijos',\n",
        "        'barrio',\n",
        "    ]\n",
        ")\n",
        "\n",
        "df[mask] = df[mask].replace(no_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p-ZIlN94gXS5"
      },
      "outputs": [],
      "source": [
        "# Personas con edad suficiente para trabajar\n",
        "df = df[~df['estado_laboral'].str.contains('Menores de 14 a침os')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPcsRlMRgXQU",
        "outputId": "9a4926c9-e945-42c8-ead3-77b964974f0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "84000.0\n"
          ]
        }
      ],
      "source": [
        "# Eliminar outliers en los sueldos\n",
        "quantil_99 = df['sueldo'].quantile(0.99)\n",
        "print(quantil_99)\n",
        "\n",
        "df = df[df['sueldo'] < quantil_99]\n",
        "\n",
        "quartil_1 = df['sueldo'].quantile(0.25)\n",
        "quartil_3 = df['sueldo'].quantile(0.75)\n",
        "\n",
        "iqr = quartil_3 - quartil_1\n",
        "\n",
        "df = df[df['sueldo'] < quartil_3 + 1.5 * iqr]\n",
        "\n",
        "df = df[df['sueldo'] > quartil_1 - 1.5 * iqr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Cfg__oLjgXNp"
      },
      "outputs": [],
      "source": [
        "# Creamos categorias con rangos de sueldos y edades\n",
        "df['rango_sueldos'] = pd.qcut(df['sueldo'], q=10, duplicates='drop').cat.codes\n",
        "\n",
        "df['rango_edades'] = pd.qcut(df['edad'], q=10).cat.codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "laWobK2YgXLD"
      },
      "outputs": [],
      "source": [
        "# Nos quedamos con las columnas que vamos a usar para el modelo\n",
        "df = df.drop(['id_hogar','nper','sueldo'], axis=1)\n",
        "\n",
        "# Removemos indice para tener un mejor orden de tratamiento\n",
        "df = df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzapmvMsgXId",
        "outputId": "ed6b5bf7-b040-4ec0-f440-7f8b7bae3d5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape (85546, 23) \n",
            "Y shape (85546,)\n"
          ]
        }
      ],
      "source": [
        "# Feautures\n",
        "X = df.drop('rango_sueldos', axis=1).to_numpy()\n",
        "y = df['rango_sueldos']\n",
        "\n",
        "print('X shape', X.shape, '\\nY shape', y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnpyZ59Lg49p",
        "outputId": "0e5c41b8-e1d2-4baa-98f7-dab9c9915c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape (85546, 23) \n",
            "Y shape (85546,)\n"
          ]
        }
      ],
      "source": [
        "# Definimos los feautures de test y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=42\n",
        ")\n",
        "\n",
        "print('X shape', X.shape, '\\nY shape', y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9QctOJZLg46u"
      },
      "outputs": [],
      "source": [
        "# Creamos el pipeline de ejecuci칩n\n",
        "one_hot = OneHotEncoder(handle_unknown = 'ignore')\n",
        "normalizer = Normalizer()\n",
        "\n",
        "pipe = Pipeline(\n",
        "    steps=[('encoder', one_hot),\n",
        "           ('normalizer', normalizer),\n",
        "           ('lightgbm', LGBMClassifier())\n",
        "           ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivu-UaR_h0_2",
        "outputId": "bf268299-872d-4f31-d708-413c5cbbcf12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "boosting_type :  gbdt\n",
            "class_weight :  None\n",
            "colsample_bytree :  1.0\n",
            "importance_type :  split\n",
            "learning_rate :  0.1\n",
            "max_depth :  -1\n",
            "min_child_samples :  20\n",
            "min_child_weight :  0.001\n",
            "min_split_gain :  0.0\n",
            "n_estimators :  100\n",
            "n_jobs :  -1\n",
            "num_leaves :  31\n",
            "objective :  None\n",
            "random_state :  None\n",
            "reg_alpha :  0.0\n",
            "reg_lambda :  0.0\n",
            "silent :  True\n",
            "subsample :  1.0\n",
            "subsample_for_bin :  200000\n",
            "subsample_freq :  0\n"
          ]
        }
      ],
      "source": [
        "#Conocemos los hypar치metros que podemos personalizar\n",
        "for key,value in LGBMClassifier().get_params().items():\n",
        "    print(key,': ', value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jYwBXQf6g44B"
      },
      "outputs": [],
      "source": [
        "# Definimos los par치metros para el cross validation\n",
        "param_grid = {\n",
        "    'lightgbm__num_leaves':[31, 62, 70],\n",
        "    'lightgbm__max_depth':[-1,5],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ-vDJkFg41d",
        "outputId": "11c9e941-d9c5-4bdd-cb6f-3c087049bc03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7758338528678305"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creamos y determinamos el score del modelo\n",
        "search = RandomizedSearchCV(pipe,\n",
        "                            param_grid,\n",
        "                            n_jobs=-1,\n",
        "                            scoring='accuracy',\n",
        "                            cv=5,\n",
        "                            n_iter=5)\n",
        "\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "search.score(X_test, y_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "tercera_entrega.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
